# Transit Data apps in various programming languages

This repository implements the same simple backend API in a variety of
languages. It's just a personal project of mine to get a feel for the languages,
and shouldn't be taken _too_ seriously.

All the apps read in the MBTA's GTFS data, which is the standard spec for
transit data - stuff like the routes, stops, and schedules for a system. The
apps look for files in an `MBTA_GTFS` folder, but could be easily updated to
work with any transit system's data. To get the MBTA data, the following
commands can be run in the repo's root directory:

```
> curl -o MBTA_GTFS.zip https://cdn.mbta.com/MBTA_GTFS.zip
> unzip -d MBTA_GTFS MBTA_GTFS.zip
```

The apps are all named some mashup of "Transit" and the programming language
name.

For now, the apps only read in the GTFS trips (~75k) and stop_times (~2M) data.
They parse the files, which are `.txt` but CSV, into an in-memory list of
structs. I was interested to see how long this takes, as it's a bunch of IO -
there are roughly 75k trips and 2 million stop_times in the MBTA data. In a
future iteration, I'd also like to handle "services", which specify which trips
run on which days, and some sort of index structure for more efficiently working
with these lists. I'm also curious to see how SoA affects performance over the
current AoS approach.

The apps currently allow a user to specify a route, which they then use to scan
through (1) the trips to see which trips are on that route, and then (2) the
stop times to see which scheduled stops are on those trips. This churns through
a bunch of structured data and I use a set for part 1. Eventually I'd like to
specify the _date_ as well, to identify which services are active, to further
narrow down the trips, and to return JSON of the schedules, rather than a simple
count.

## Data

Here are the runtimes I'm seeing so far. I've instrumented the apps to measure
two aspects: how long it takes to process the data into its internal structure,
and how long it takes to scan through the data to return an answer. Listed here
is the median of 5 runs for each app.

### Loading stop_times.txt

This is the time it takes for the app to load the stop_times.txt file, which is
roughly 100MB and 2M records and parse it into a big vector/list/array of a
structured `StopTime` structs.

| Language | Time (ms) |
| -------- | --------- |
| Deno     | 2,779     |
| Elixir   | 4,116     |
| Go       | 817       |
| Rust     | 431       |

### Scanning the data

This is the time it takes to scan through the in-memory list of Trips for all
those that belong to route_id Red, and then count up all the StopTimes that
belong to those trips.

| Language | Time (ms) |
| -------- | --------- |
| Deno     | 61        |
| Elixir   | 59        |
| Go       | 35        |
| Rust     | 17        |

## Thoughts

Here are some scattered thoughts while I went about writing this.

### Deno

Deno is pretty neat. I really want it to succeed. I really like TypeScript, and
Deno almost gives me what I want: pretending TypeScript is a full-fledged
language, with a standard library, that I can build non-frontend apps with.
Let's just sweep all that JS-heritage and V8 stuff under the rug...

I wish the standard library weren't at URLs like all the other packages. It
would be great if the `deno` tool you downloaded also included the standard
library, and you could just reference it without any network stuff. The
documentation is also pretty cryptic (and I think autogenerated?).

The package management stuff I haven't quite wrapped my head around. Obviously,
you shouldn't be downloading stuff willy-nilly, but I think with some
combination of the conventional deps.ts, import_map, specifying a lock file, the
vendor command, --no-remote, etc, I feel like I have all the pieces to kind of
build up a reasonable approach, but I don't quite understand it all just yet.

Personally, the `--allow-read`, `--allow-net`, etc stuff feels a little gimmicky
to me. I don't think other languages really have that, and I'm not sure what the
threat model is here. I control the backend code, and if I'm worried about my
code doing unexpected things like that I have larger issues. I just run with
`-A` all the time.

### Elixir

Elixir is my primary language, so I threw this one in to compare its performance
to see what I could be missing. I like Elixir the language and all its nice OTP
goodies, but it's known to be a little slow, so I was wondering how much
performance I'm leaving on the table.

### Go

I was super happy to get the work done so far using just the standard library.

That said, contrary to my expectations, I found the documentation not great.
While the language reference and tour was pretty good and useful (I kept
referring to the tour), the library documentation on
[pkg.go.dev](https://pkg.go.dev/) was fairly... bad.

It took me longer than I'd like to admit to figure out how to get a dang
`io.Reader`, which is what the CSV parsing package takes. I had hoped
[searching their docs](https://pkg.go.dev/search?q=io.reader) for `io.Reader`
would yield a package or function that at a glance would (1) read from the
filesystem and (2) implement the `io.Reader` interface, but the top result was
simply the definition of the interface, and the rest of the results were random
GitHub repos. And clicking through to the `io.Reader` definition didn't provide
links to anything that implements it. Eventually I gave up and went the other
direction, trying to figure out how to open and read files. I finally found
`os.Open()` (though it was my third try after poking around in `io` and
`io.fs`). I saw it returns a `File`, which then sent me on a bit of a goose
change on how to turn _it_ into an `io.Reader` before realizing that although
it's not mentioned in the docs, the type _does_ implement `Read` and so it _is_
already an `io.Reader`! It was all sort of magical to me, and kind of odd. Now I
realize that in theory I could have searched pkg.go.dev for "Read" to find types
that implement it, and hence satisfy `io.Reader` and would get me to `File` and
`os.Open()` but of course that doesn't work because the search function seems to
be hot garbage.

All that said, actually programming in Go was pretty nice. VSCode support was
solid and the build/run cycle was fast! The final result ended up being pretty
quick, too. It doesn't have the type richness I appreciate, but I didn't mind it
overall.

### Rust

This one blew me away. I was expecting a lot more low level fiddlyness, but was
prepared to allocate and clone and do all the tricks I've read about to not
worry about eking out the most performance possible. After all, I'm comparing
against higher level interpreted or GC languages, and am interested in Rust more
for its type system than needing to program at a system level.

All that said, the performance ended up better than all the others, even with
ample String cloning, and was just as easy to do! That said, I've had some
experience playing with Rust in the past, so it wasn't brand new to me, but it
has been some time so I was expecting too be a lot more, uh... rusty.

Also, I don't know how much of this is because Rust is special or because
BurntSushi is a national treasure and his CSV library is impeccably constructed
and documented.

I also was impressed and amused that I got compiler warnings that my Struct had
unnecessary fields (I haven't used the Trips' service_ids or the StopTimes'
arrival and departure times yet), which wasn't raised for any of the other
languages.
